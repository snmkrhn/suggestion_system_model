{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2415872,"sourceType":"datasetVersion","datasetId":1461623}],"dockerImageVersionId":30786,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/sinemkarahan/suggestion-system?scriptVersionId=206520130\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:28:51.582872Z","iopub.execute_input":"2024-11-11T09:28:51.583276Z","iopub.status.idle":"2024-11-11T09:28:52.778867Z","shell.execute_reply.started":"2024-11-11T09:28:51.583235Z","shell.execute_reply":"2024-11-11T09:28:52.777569Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/amazon-product-reviews/Reviews.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\n\n# Veri setinin bulunduğu dizini listeler\n# Bu dizin, Kaggle Notebook'ta veri setlerinin varsayılan olarak bulunduğu dizindir\nbase_path = '/kaggle/input/'\n\n# Mevcut veri seti klasörlerini ve dosyalarını listeler\nfor dirname, _, filenames in os.walk(base_path):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:28:52.780758Z","iopub.execute_input":"2024-11-11T09:28:52.781221Z","iopub.status.idle":"2024-11-11T09:28:52.787981Z","shell.execute_reply.started":"2024-11-11T09:28:52.781183Z","shell.execute_reply":"2024-11-11T09:28:52.786963Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/amazon-product-reviews/Reviews.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\n\n# Veri setini doğru yoldan yükleyelim\ndata = pd.read_csv('/kaggle/input/amazon-product-reviews/Reviews.csv')\n\n# İlk birkaç satırı inceleyelim\ndata.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:28:52.789552Z","iopub.execute_input":"2024-11-11T09:28:52.790354Z","iopub.status.idle":"2024-11-11T09:29:00.972343Z","shell.execute_reply.started":"2024-11-11T09:28:52.790302Z","shell.execute_reply":"2024-11-11T09:29:00.970852Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n\n                 Summary                                               Text  \n0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n2  \"Delight\" says it all  This is a confection that has been around a fe...  \n3         Cough Medicine  If you are looking for the secret ingredient i...  \n4            Great taffy  Great taffy at a great price.  There was a wid...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# Eksik değerleri kontrol etme\nmissing_values = data.isnull().sum()\nprint(missing_values)\n\n# Eksik değer içeren satırları kaldırma\ndata = data.dropna()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:29:00.975575Z","iopub.execute_input":"2024-11-11T09:29:00.976059Z","iopub.status.idle":"2024-11-11T09:29:01.432511Z","shell.execute_reply.started":"2024-11-11T09:29:00.97601Z","shell.execute_reply":"2024-11-11T09:29:01.431541Z"}},"outputs":[{"name":"stdout","text":"Id                         0\nProductId                  0\nUserId                     0\nProfileName               26\nHelpfulnessNumerator       0\nHelpfulnessDenominator     0\nScore                      0\nTime                       0\nSummary                   27\nText                       0\ndtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import pandas as pd\nimport re\n\n# Temel bir stopwords listesi oluşturalım\ncustom_stopwords = [\n    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n    'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n    'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n    'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n    'was', 'were', 'be', 'been', 'being', 'if', 'then', 'that', 'the', 'and', 'but', 'or',\n    'as', 'at', 'for', 'by', 'with', 'about', 'against', 'between', 'into', 'through',\n    'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', \n    'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n    'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n    'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n    'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'\n]\n\n# Eksik değerleri dolduralım\ndata['ProfileName'] = data['ProfileName'].fillna('Bilinmiyor')\ndata['Summary'] = data['Summary'].fillna('Bilinmiyor')\ndata['Text'] = data['Text'].fillna('Bilinmiyor')\n\ndef clean_text(text):\n    # Küçük harfe çevir\n    text = text.lower()\n    # Noktalama işaretlerini ve rakamları temizle\n    text = re.sub(r'[^a-z\\s]', '', text)\n    # Stopwords'leri temizle\n    text = ' '.join(word for word in text.split() if word not in custom_stopwords)\n    return text\n\n# 'Summary' ve 'Text' sütunlarını temizleyelim\ndata['Cleaned_Summary'] = data['Summary'].apply(clean_text)\ndata['Cleaned_Text'] = data['Text'].apply(clean_text)\n\n# Temizlenmiş verileri kontrol edelim\ncleaned_data_preview = data[['Cleaned_Summary', 'Cleaned_Text']].head()\nprint(cleaned_data_preview)\n\n\n\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:29:01.434042Z","iopub.execute_input":"2024-11-11T09:29:01.434504Z","iopub.status.idle":"2024-11-11T09:30:18.631968Z","shell.execute_reply.started":"2024-11-11T09:29:01.434454Z","shell.execute_reply":"2024-11-11T09:30:18.630828Z"}},"outputs":[{"name":"stdout","text":"         Cleaned_Summary                                       Cleaned_Text\n0  good quality dog food  have bought several of vitality canned dog foo...\n1             advertised  product arrived labeled jumbo salted peanutsth...\n2           delight says  a confection has around a centuries a light pi...\n3         cough medicine  looking secret ingredient robitussin believe h...\n4            great taffy  great taffy a great price a wide assortment of...\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Özellikler ve hedef değişken\nX = data['Cleaned_Text']\ny = data['Score']  # ya da uygun bir hedef değişkeni\n\n# Eğitim ve test setlerine ayırma\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:30:18.633417Z","iopub.execute_input":"2024-11-11T09:30:18.633829Z","iopub.status.idle":"2024-11-11T09:30:19.357322Z","shell.execute_reply.started":"2024-11-11T09:30:18.633789Z","shell.execute_reply":"2024-11-11T09:30:19.356151Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# TfidfVectorizer ile metin verisini sayısal hale getirme\nvectorizer = TfidfVectorizer(max_features=5000)  # En fazla 5000 kelime ile sınırlıyoruz\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)  # Test verisini dönüştür\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:30:19.358712Z","iopub.execute_input":"2024-11-11T09:30:19.359242Z","iopub.status.idle":"2024-11-11T09:30:44.95412Z","shell.execute_reply.started":"2024-11-11T09:30:19.359203Z","shell.execute_reply":"2024-11-11T09:30:44.952855Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\n\n# Naive Bayes modelini oluşturma ve eğitme\nnb_model = MultinomialNB()\nnb_model.fit(X_train_tfidf, y_train)\n\n# Test seti ile tahmin yapma\ny_pred = nb_model.predict(X_test_tfidf)\n\n# Model performansını değerlendirme\nprint(\"Doğruluk Skoru:\", accuracy_score(y_test, y_pred))\nprint(\"\\nSınıflandırma Raporu:\\n\", classification_report(y_test, y_pred))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:30:44.955506Z","iopub.execute_input":"2024-11-11T09:30:44.955923Z","iopub.status.idle":"2024-11-11T09:30:45.390336Z","shell.execute_reply.started":"2024-11-11T09:30:44.955872Z","shell.execute_reply":"2024-11-11T09:30:45.38895Z"}},"outputs":[{"name":"stdout","text":"Doğruluk Skoru: 0.6717745269658079\n\nSınıflandırma Raporu:\n               precision    recall  f1-score   support\n\n           1       0.71      0.32      0.44     10515\n           2       0.58      0.01      0.02      5937\n           3       0.51      0.02      0.04      8460\n           4       0.45      0.03      0.06     16026\n           5       0.67      0.99      0.80     72743\n\n    accuracy                           0.67    113681\n   macro avg       0.58      0.27      0.27    113681\nweighted avg       0.63      0.67      0.57    113681\n\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Test yorumları\nsample_reviews = [\n    \"This product is amazing, I loved it!\",  # Olumlu bir yorum\n    \"The quality is really bad, I'm disappointed.\",  # Olumsuz bir yorum\n    \"It's okay, not the best but works.\",  # Nötr bir yorum\n    \"Terrible experience, would not recommend.\"  # Çok olumsuz bir yorum\n]\n\n# Yorumları sayısal hale getirme\nsample_reviews_tfidf = vectorizer.transform(sample_reviews)\n\n# Model ile tahmin yapma\npredictions = nb_model.predict(sample_reviews_tfidf)\n\n# Sonuçları yazdırma\nfor review, pred in zip(sample_reviews, predictions):\n    print(f\"Review: '{review}' -> Tahmin edilen sınıf: {pred}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:30:45.392113Z","iopub.execute_input":"2024-11-11T09:30:45.392457Z","iopub.status.idle":"2024-11-11T09:30:45.40116Z","shell.execute_reply.started":"2024-11-11T09:30:45.392421Z","shell.execute_reply":"2024-11-11T09:30:45.399986Z"}},"outputs":[{"name":"stdout","text":"Review: 'This product is amazing, I loved it!' -> Tahmin edilen sınıf: 5\nReview: 'The quality is really bad, I'm disappointed.' -> Tahmin edilen sınıf: 5\nReview: 'It's okay, not the best but works.' -> Tahmin edilen sınıf: 5\nReview: 'Terrible experience, would not recommend.' -> Tahmin edilen sınıf: 1\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nimport pandas as pd\n\n# Kelime frekanslarını hesaplamak için CountVectorizer kullan\ncount_vectorizer = CountVectorizer(stop_words='english')\nX_counts = count_vectorizer.fit_transform(data['Cleaned_Text'])\nsum_words = X_counts.sum(axis=0)  # Kelime frekanslarını topla\nwords_freq = [(word, sum_words[0, idx]) for word, idx in count_vectorizer.vocabulary_.items()]\nwords_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n\n# En sık geçen kelimeleri göster\ndf_words = pd.DataFrame(words_freq, columns=['Word', 'Frequency'])\nprint(df_words.head(10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:30:45.409931Z","iopub.execute_input":"2024-11-11T09:30:45.41032Z","iopub.status.idle":"2024-11-11T09:31:11.047741Z","shell.execute_reply.started":"2024-11-11T09:30:45.410283Z","shell.execute_reply":"2024-11-11T09:31:11.046483Z"}},"outputs":[{"name":"stdout","text":"      Word  Frequency\n0       br     272674\n1     like     251867\n2     good     195341\n3    taste     166576\n4    great     163565\n5   coffee     160186\n6  product     146450\n7   flavor     142559\n8      tea     133105\n9     love     126644\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"from textblob import TextBlob\n\n# Duygu analizini gerçekleştiren fonksiyon\ndef analyze_sentiment(review):\n    analysis = TextBlob(review)\n    if analysis.sentiment.polarity > 0:\n        return 'positive'\n    elif analysis.sentiment.polarity < 0:\n        return 'negative'\n    else:\n        return 'neutral'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:31:11.049023Z","iopub.execute_input":"2024-11-11T09:31:11.049345Z","iopub.status.idle":"2024-11-11T09:31:11.718321Z","shell.execute_reply.started":"2024-11-11T09:31:11.04931Z","shell.execute_reply":"2024-11-11T09:31:11.716909Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\n# Yorumlardan anahtar kelime çıkarma\ndef extract_keywords(reviews):\n    vectorizer = TfidfVectorizer(max_features=10)  # En fazla 10 anahtar kelime çıkar\n    X = vectorizer.fit_transform(reviews)\n    return vectorizer.get_feature_names_out()\n\n# Örnek kullanımı\nreviews = [\"The product has great taste but is too expensive.\",\n           \"The quality of the material is poor.\"]\nkeywords = extract_keywords(reviews)\nprint(keywords)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:31:11.719971Z","iopub.execute_input":"2024-11-11T09:31:11.720353Z","iopub.status.idle":"2024-11-11T09:31:11.731201Z","shell.execute_reply.started":"2024-11-11T09:31:11.720314Z","shell.execute_reply":"2024-11-11T09:31:11.729969Z"}},"outputs":[{"name":"stdout","text":"['but' 'expensive' 'great' 'has' 'is' 'material' 'of' 'poor' 'product'\n 'the']\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom nltk.corpus import stopwords\nimport nltk\n\n# Eğer ilk kez kullanıyorsanız aşağıdaki satırı çalıştırın:\n# nltk.download('stopwords')\n\n# Stopwords listesini alıyoruz\nstop_words = list(stopwords.words('english'))\n\n# TF-IDF vektörleştiriciyi stopwords ile güncelliyoruz\nvectorizer = TfidfVectorizer(max_features=10, stop_words=stop_words)\nX = vectorizer.fit_transform(data['Cleaned_Text'])\n\n# Anahtar kelimeleri yeniden çıkarma\nkeywords = vectorizer.get_feature_names_out()\nprint(keywords)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:31:11.732841Z","iopub.execute_input":"2024-11-11T09:31:11.733367Z","iopub.status.idle":"2024-11-11T09:31:37.791951Z","shell.execute_reply.started":"2024-11-11T09:31:11.733323Z","shell.execute_reply":"2024-11-11T09:31:37.790636Z"}},"outputs":[{"name":"stdout","text":"['br' 'coffee' 'flavor' 'good' 'great' 'like' 'one' 'product' 'taste'\n 'tea']\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"from textblob import TextBlob\n\n# Yorumun pozitif, negatif veya nötr olup olmadığını belirleyen fonksiyon\ndef analyze_sentiment(review):\n    analysis = TextBlob(review)\n    if analysis.sentiment.polarity > 0:\n        return 'positive'\n    elif analysis.sentiment.polarity < 0:\n        return 'negative'\n    else:\n        return 'neutral'\n\n# Yorumlar üzerinde uygulama\ndata['Sentiment'] = data['Cleaned_Text'].apply(analyze_sentiment)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:31:37.79325Z","iopub.execute_input":"2024-11-11T09:31:37.793623Z","iopub.status.idle":"2024-11-11T09:35:35.952226Z","shell.execute_reply.started":"2024-11-11T09:31:37.79358Z","shell.execute_reply":"2024-11-11T09:35:35.951019Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# Sonuçları kontrol et\nprint(data[['Cleaned_Text', 'Sentiment']].head(10))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:35:35.954018Z","iopub.execute_input":"2024-11-11T09:35:35.954385Z","iopub.status.idle":"2024-11-11T09:35:36.002215Z","shell.execute_reply.started":"2024-11-11T09:35:35.954346Z","shell.execute_reply":"2024-11-11T09:35:36.001085Z"}},"outputs":[{"name":"stdout","text":"                                        Cleaned_Text Sentiment\n0  have bought several of vitality canned dog foo...  positive\n1  product arrived labeled jumbo salted peanutsth...  positive\n2  a confection has around a centuries a light pi...  positive\n3  looking secret ingredient robitussin believe h...  positive\n4  great taffy a great price a wide assortment of...  positive\n5  got a wild hair taffy ordered five pound bag t...  positive\n6  saltwater taffy had great flavors soft chewy c...  positive\n7  taffy good soft chewy flavors amazing would de...  positive\n8  right im mostly sprouting cats eat grass love ...  positive\n9  a healthy dog food good digestion also good sm...  positive\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Örnek bir yorum için\nsample_review = \"This product is bad!\"\nprint(analyze_sentiment(sample_review))  # 'positive' bekleniyor\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:35:36.003421Z","iopub.execute_input":"2024-11-11T09:35:36.003786Z","iopub.status.idle":"2024-11-11T09:35:36.009757Z","shell.execute_reply.started":"2024-11-11T09:35:36.003749Z","shell.execute_reply":"2024-11-11T09:35:36.008574Z"}},"outputs":[{"name":"stdout","text":"negative\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport pandas as pd\n\n# Yorumları alıyoruz (Cleaned_Text sütunu)\ncorpus = data['Cleaned_Text']\n\n# TF-IDF vektörleştirici ile anahtar kelimeleri çıkarma\ntfidf_vectorizer = TfidfVectorizer(max_df=0.9, min_df=0.05, stop_words='english', ngram_range=(1,2))\ntfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n\n# Anahtar kelimeleri alıyoruz\nfeature_names = tfidf_vectorizer.get_feature_names_out()\n\n# Anahtar kelimeleri DataFrame'e çeviriyoruz\ntfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n\n# Yorum başına en yüksek TF-IDF skora sahip kelimeleri alıyoruz\nimportant_keywords = tfidf_df.idxmax(axis=1)\ndata['Keywords'] = important_keywords\n\nprint(data[['Cleaned_Text', 'Sentiment', 'Keywords']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:35:36.01101Z","iopub.execute_input":"2024-11-11T09:35:36.011431Z","iopub.status.idle":"2024-11-11T09:36:35.95939Z","shell.execute_reply.started":"2024-11-11T09:35:36.011384Z","shell.execute_reply":"2024-11-11T09:36:35.95814Z"}},"outputs":[{"name":"stdout","text":"                                        Cleaned_Text Sentiment Keywords\n0  have bought several of vitality canned dog foo...  positive   better\n1  product arrived labeled jumbo salted peanutsth...  positive  product\n2  a confection has around a centuries a light pi...  positive    sugar\n3  looking secret ingredient robitussin believe h...  positive  ordered\n4  great taffy a great price a wide assortment of...  positive    great\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"import pandas as pd\n\ndata = pd.read_csv('/kaggle/input/amazon-product-reviews/Reviews.csv')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:36:35.960664Z","iopub.execute_input":"2024-11-11T09:36:35.96104Z","iopub.status.idle":"2024-11-11T09:36:40.539088Z","shell.execute_reply.started":"2024-11-11T09:36:35.961002Z","shell.execute_reply":"2024-11-11T09:36:40.537814Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"print(data.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:36:40.540348Z","iopub.execute_input":"2024-11-11T09:36:40.540679Z","iopub.status.idle":"2024-11-11T09:36:40.546561Z","shell.execute_reply.started":"2024-11-11T09:36:40.540644Z","shell.execute_reply":"2024-11-11T09:36:40.545413Z"}},"outputs":[{"name":"stdout","text":"Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"data['Sentiment'] = data['Text'].apply(analyze_sentiment)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:36:40.54835Z","iopub.execute_input":"2024-11-11T09:36:40.548821Z","iopub.status.idle":"2024-11-11T09:43:32.218713Z","shell.execute_reply.started":"2024-11-11T09:36:40.54877Z","shell.execute_reply":"2024-11-11T09:43:32.217582Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(analyze_sentiment(\"This product is great!\"))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:43:32.220258Z","iopub.execute_input":"2024-11-11T09:43:32.22074Z","iopub.status.idle":"2024-11-11T09:43:32.227016Z","shell.execute_reply.started":"2024-11-11T09:43:32.22069Z","shell.execute_reply":"2024-11-11T09:43:32.225851Z"}},"outputs":[{"name":"stdout","text":"positive\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"data['Sentiment'] = data['Text'].apply(analyze_sentiment)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:43:32.22825Z","iopub.execute_input":"2024-11-11T09:43:32.22858Z","iopub.status.idle":"2024-11-11T09:50:25.984688Z","shell.execute_reply.started":"2024-11-11T09:43:32.228545Z","shell.execute_reply":"2024-11-11T09:50:25.983418Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"print(data[['Text', 'Sentiment']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:50:25.986208Z","iopub.execute_input":"2024-11-11T09:50:25.986608Z","iopub.status.idle":"2024-11-11T09:50:26.028011Z","shell.execute_reply.started":"2024-11-11T09:50:25.986559Z","shell.execute_reply":"2024-11-11T09:50:26.026891Z"}},"outputs":[{"name":"stdout","text":"                                                Text Sentiment\n0  I have bought several of the Vitality canned d...  positive\n1  Product arrived labeled as Jumbo Salted Peanut...  negative\n2  This is a confection that has been around a fe...  positive\n3  If you are looking for the secret ingredient i...  positive\n4  Great taffy at a great price.  There was a wid...  positive\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"import pandas as pd\n\n# DataFrame'iniz burada, örneğin:\ndata = pd.read_csv('/kaggle/input/amazon-product-reviews/Reviews.csv')\n\n# Duygu analizi uygulama fonksiyonu (örnek)\ndef analyze_sentiment(text):\n    # Basit bir duygu analizi\n    if \"not\" in text or \"bad\" in text:\n        return 'negative'\n    elif \"good\" in text or \"great\" in text:\n        return 'positive'\n    else:\n        return 'neutral'\n\n# Duygu analizini uygulama\ndata['Sentiment'] = data['Text'].apply(analyze_sentiment)\n\n# Öneri oluşturma fonksiyonu\ndef generate_suggestion(sentiment, review_text):\n    if sentiment == 'negative':\n        return f\"Improvement could be made regarding the issues mentioned in your review: '{review_text}'.\"\n    elif sentiment == 'neutral':\n        return f\"Consider enhancing the aspects mentioned in your review: '{review_text}'.\"\n    else:\n        return f\"Thank you for your positive feedback on: '{review_text}'!\"\n\n# Her yorum için öneri oluşturma\ndata['Suggestion'] = data.apply(lambda row: generate_suggestion(row['Sentiment'], row['Text']), axis=1)\n\n# Sonuçları görüntüleme\nprint(data[['Text', 'Sentiment', 'Suggestion']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:50:26.029454Z","iopub.execute_input":"2024-11-11T09:50:26.029863Z","iopub.status.idle":"2024-11-11T09:50:37.695137Z","shell.execute_reply.started":"2024-11-11T09:50:26.029823Z","shell.execute_reply":"2024-11-11T09:50:37.693827Z"}},"outputs":[{"name":"stdout","text":"                                                Text Sentiment  \\\n0  I have bought several of the Vitality canned d...  positive   \n1  Product arrived labeled as Jumbo Salted Peanut...   neutral   \n2  This is a confection that has been around a fe...   neutral   \n3  If you are looking for the secret ingredient i...  positive   \n4  Great taffy at a great price.  There was a wid...  positive   \n\n                                          Suggestion  \n0  Thank you for your positive feedback on: 'I ha...  \n1  Consider enhancing the aspects mentioned in yo...  \n2  Consider enhancing the aspects mentioned in yo...  \n3  Thank you for your positive feedback on: 'If y...  \n4  Thank you for your positive feedback on: 'Grea...  \n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"# Güncellenmiş öneri oluşturma fonksiyonu\ndef generate_detailed_suggestion(sentiment, review_text):\n    if sentiment == 'negative':\n        return (f\"We appreciate your feedback. To improve your experience, could you please share more details about the issues you faced in: '{review_text}'?\")\n    elif sentiment == 'neutral':\n        return (f\"Thank you for your insights. We encourage you to explore additional features or products that might meet your expectations regarding: '{review_text}'.\")\n    else:\n        return (f\"Thank you for your positive feedback! We're thrilled to hear you enjoyed: '{review_text}'. You might also like to try our other flavors or products!\")\n\n# Her yorum için öneri oluşturma\ndata['Suggestion'] = data.apply(lambda row: generate_detailed_suggestion(row['Sentiment'], row['Text']), axis=1)\n\n# Sonuçları görüntüleme\nprint(data[['Text', 'Sentiment', 'Suggestion']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:50:37.696415Z","iopub.execute_input":"2024-11-11T09:50:37.696769Z","iopub.status.idle":"2024-11-11T09:50:44.551477Z","shell.execute_reply.started":"2024-11-11T09:50:37.696733Z","shell.execute_reply":"2024-11-11T09:50:44.550254Z"}},"outputs":[{"name":"stdout","text":"                                                Text Sentiment  \\\n0  I have bought several of the Vitality canned d...  positive   \n1  Product arrived labeled as Jumbo Salted Peanut...   neutral   \n2  This is a confection that has been around a fe...   neutral   \n3  If you are looking for the secret ingredient i...  positive   \n4  Great taffy at a great price.  There was a wid...  positive   \n\n                                          Suggestion  \n0  Thank you for your positive feedback! We're th...  \n1  Thank you for your insights. We encourage you ...  \n2  Thank you for your insights. We encourage you ...  \n3  Thank you for your positive feedback! We're th...  \n4  Thank you for your positive feedback! We're th...  \n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"import pandas as pd\nfrom textblob import TextBlob\n\n# Veri setini yükleme\ndata = pd.read_csv('/kaggle/input/amazon-product-reviews/Reviews.csv')\n\n# Duygu analizi fonksiyonu\ndef analyze_sentiment(text):\n    analysis = TextBlob(text)\n    if analysis.sentiment.polarity > 0:\n        return 'positive'\n    elif analysis.sentiment.polarity < 0:\n        return 'negative'\n    else:\n        return 'neutral'\n\n# Duygu analizi uygulama\ndata['Sentiment'] = data['Text'].apply(analyze_sentiment)\n\n# Öneri oluşturma fonksiyonu\ndef generate_detailed_suggestion(sentiment, review_text):\n    if sentiment == 'negative':\n        return (f\"We appreciate your feedback on: '{review_text}'. We're sorry to hear about your experience. Can you please share more details so we can address this issue?\")\n    elif sentiment == 'neutral':\n        return (f\"Thank you for your insights on: '{review_text}'. To enhance your experience, we recommend exploring additional features or products.\")\n    else:  # positive\n        return (f\"Thank you for your wonderful feedback on: '{review_text}'. We're thrilled you enjoyed it! Have you tried our other products?\")\n\n# Öneri sütununu doldurma\ndata['Suggestion'] = data.apply(lambda row: generate_detailed_suggestion(row['Sentiment'], row['Text']), axis=1)\n\n# Çıktıyı görüntüleme\nprint(data[['Text', 'Sentiment', 'Suggestion']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:50:44.552993Z","iopub.execute_input":"2024-11-11T09:50:44.553377Z","iopub.status.idle":"2024-11-11T09:57:52.938011Z","shell.execute_reply.started":"2024-11-11T09:50:44.553337Z","shell.execute_reply":"2024-11-11T09:57:52.936694Z"}},"outputs":[{"name":"stdout","text":"                                                Text Sentiment  \\\n0  I have bought several of the Vitality canned d...  positive   \n1  Product arrived labeled as Jumbo Salted Peanut...  negative   \n2  This is a confection that has been around a fe...  positive   \n3  If you are looking for the secret ingredient i...  positive   \n4  Great taffy at a great price.  There was a wid...  positive   \n\n                                          Suggestion  \n0  Thank you for your wonderful feedback on: 'I h...  \n1  We appreciate your feedback on: 'Product arriv...  \n2  Thank you for your wonderful feedback on: 'Thi...  \n3  Thank you for your wonderful feedback on: 'If ...  \n4  Thank you for your wonderful feedback on: 'Gre...  \n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"import random\n\n# Kullanıcı isimleri ve alışveriş geçmişini simüle etme\nuser_names = ['Alice', 'Bob', 'Charlie', 'Daisy', 'Eve']\npurchase_histories = [\"Vitality canned dog food\", \"Jumbo Salted Peanuts\", \"Confection\", \"Secret ingredient\", \"Taffy\"]\n\n# Rastgele isim ve geçmiş ekleyerek veri çerçevesini doldurma\ndata['User_Name'] = [random.choice(user_names) for _ in range(len(data))]\ndata['Purchase_History'] = [random.choice(purchase_histories) for _ in range(len(data))]\n\n# Geliştirilmiş öneri fonksiyonu\ndef generate_personalized_suggestion(sentiment, review_text, user_name, purchase_history):\n    keywords = [\"delivery\", \"quality\", \"taste\", \"packaging\", \"price\"]\n    matched_keywords = [word for word in keywords if word in review_text.lower()]\n\n    if sentiment == 'negative':\n        if matched_keywords:\n            suggestion = (f\"{user_name}, we appreciate your feedback on your purchase of '{purchase_history}'. \"\n                          f\"We're sorry to hear about issues with {', '.join(matched_keywords)}. \"\n                          \"Our team is working to address these concerns. Meanwhile, please check if there's an alternative product that may suit your needs.\")\n        else:\n            suggestion = (f\"{user_name}, we're sorry to hear about your experience with '{purchase_history}'. \"\n                          \"We appreciate more details to help us improve.\")\n        suggestion += \" Please consider reaching out to our support team for immediate assistance.\"\n\n    elif sentiment == 'neutral':\n        suggestion = (f\"Thank you for your insights on '{purchase_history}', {user_name}. \"\n                      \"We recommend exploring related products or additional features to enhance your experience.\")\n\n    else:  # positive\n        suggestion = (f\"Thank you for your wonderful feedback, {user_name}! We're thrilled that you enjoyed '{purchase_history}'. \"\n                      \"Have you tried similar products in our range? We think you might enjoy them too!\")\n\n    return suggestion\n\n# Güncellenmiş öneri sütununu doldurma\ndata['Suggestion'] = data.apply(lambda row: generate_personalized_suggestion(row['Sentiment'], row['Text'], row['User_Name'], row['Purchase_History']), axis=1)\n\n# Çıktıyı görüntüleme\nprint(data[['User_Name', 'Purchase_History', 'Text', 'Sentiment', 'Suggestion']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:57:52.939771Z","iopub.execute_input":"2024-11-11T09:57:52.940263Z","iopub.status.idle":"2024-11-11T09:58:06.958447Z","shell.execute_reply.started":"2024-11-11T09:57:52.940209Z","shell.execute_reply":"2024-11-11T09:58:06.956996Z"}},"outputs":[{"name":"stdout","text":"  User_Name          Purchase_History  \\\n0     Daisy  Vitality canned dog food   \n1     Daisy                     Taffy   \n2     Alice         Secret ingredient   \n3     Daisy         Secret ingredient   \n4       Bob                     Taffy   \n\n                                                Text Sentiment  \\\n0  I have bought several of the Vitality canned d...  positive   \n1  Product arrived labeled as Jumbo Salted Peanut...  negative   \n2  This is a confection that has been around a fe...  positive   \n3  If you are looking for the secret ingredient i...  positive   \n4  Great taffy at a great price.  There was a wid...  positive   \n\n                                          Suggestion  \n0  Thank you for your wonderful feedback, Daisy! ...  \n1  Daisy, we're sorry to hear about your experien...  \n2  Thank you for your wonderful feedback, Alice! ...  \n3  Thank you for your wonderful feedback, Daisy! ...  \n4  Thank you for your wonderful feedback, Bob! We...  \n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"import pandas as pd\nfrom textblob import TextBlob\nimport random\n\n# Veri setini yükleme\ndata = pd.read_csv('/kaggle/input/amazon-product-reviews/Reviews.csv')\n\n# Duygu analizi fonksiyonu\ndef analyze_sentiment(text):\n    analysis = TextBlob(text)\n    if analysis.sentiment.polarity > 0:\n        return 'positive'\n    elif analysis.sentiment.polarity < 0:\n        return 'negative'\n    else:\n        return 'neutral'\n\n# Duygu analizini uygulama\ndata['Sentiment'] = data['Text'].apply(analyze_sentiment)\n\n# Kullanıcı isimleri ve alışveriş geçmişini simüle etme\nuser_names = ['Alice', 'Bob', 'Charlie', 'Daisy', 'Eve']\npurchase_histories = [\"Vitality canned dog food\", \"Jumbo Salted Peanuts\", \"Confection\", \"Secret ingredient\", \"Taffy\"]\n\n# Rastgele isim ve geçmiş ekleyerek veri çerçevesini doldurma\ndata['User_Name'] = [random.choice(user_names) for _ in range(len(data))]\ndata['Purchase_History'] = [random.choice(purchase_histories) for _ in range(len(data))]\n\n# Geliştirilmiş öneri fonksiyonu\ndef generate_personalized_suggestion(sentiment, review_text, user_name, purchase_history):\n    keywords = [\"delivery\", \"quality\", \"taste\", \"packaging\", \"price\"]\n    matched_keywords = [word for word in keywords if word in review_text.lower()]\n\n    # Negatif yorumlar için\n    if sentiment == 'negative':\n        if matched_keywords:\n            suggestion = (f\"{user_name}, we appreciate your feedback on your purchase of '{purchase_history}'. \"\n                          f\"We're sorry to hear about issues with {', '.join(matched_keywords)}. \"\n                          \"Our team is working to address these concerns. \")\n            # Özel anahtar kelimelere göre ekstra tavsiye isteme\n            if 'delivery' in matched_keywords:\n                suggestion += \"Could you provide more details on the delivery issue so we can improve it? \"\n            if 'quality' in matched_keywords:\n                suggestion += \"Can you tell us what aspects of the quality could be enhanced? \"\n            if 'taste' in matched_keywords:\n                suggestion += \"Could you specify what could be improved in the flavor? \"\n            if 'packaging' in matched_keywords:\n                suggestion += \"If the packaging didn't meet your expectations, let us know how we can make it better. \"\n            if 'price' in matched_keywords:\n                suggestion += \"We strive to offer value; any suggestions on pricing are welcome! \"\n        else:\n            suggestion = (f\"{user_name}, we're sorry to hear about your experience with '{purchase_history}'. \"\n                          \"We would love to hear more details to help us improve.\")\n        suggestion += \" Please consider reaching out to our support team for immediate assistance.\"\n\n    # Nötr yorumlar için\n    elif sentiment == 'neutral':\n        suggestion = (f\"Thank you for your insights on '{purchase_history}', {user_name}. \"\n                      \"To enhance your experience, we recommend exploring additional features or products similar to what you've tried.\")\n\n    # Pozitif yorumlar için\n    else:  # positive\n        suggestion = (f\"Thank you for your wonderful feedback, {user_name}! We're thrilled that you enjoyed '{purchase_history}'. \"\n                      \"Have you tried similar products in our range? \")\n        # Benzer ürün önerisi yapma\n        suggestion += f\"You might also enjoy our '{random.choice(purchase_histories)}'!\"\n\n    return suggestion\n\n# Güncellenmiş öneri sütununu doldurma\ndata['Suggestion'] = data.apply(lambda row: generate_personalized_suggestion(row['Sentiment'], row['Text'], row['User_Name'], row['Purchase_History']), axis=1)\n\n# Çıktıyı görüntüleme\nprint(data[['User_Name', 'Purchase_History', 'Text', 'Sentiment', 'Suggestion']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T09:58:06.964085Z","iopub.execute_input":"2024-11-11T09:58:06.964508Z","iopub.status.idle":"2024-11-11T10:05:21.450899Z","shell.execute_reply.started":"2024-11-11T09:58:06.964466Z","shell.execute_reply":"2024-11-11T10:05:21.44963Z"}},"outputs":[{"name":"stdout","text":"  User_Name      Purchase_History  \\\n0       Eve            Confection   \n1       Eve  Jumbo Salted Peanuts   \n2   Charlie  Jumbo Salted Peanuts   \n3       Bob                 Taffy   \n4   Charlie     Secret ingredient   \n\n                                                Text Sentiment  \\\n0  I have bought several of the Vitality canned d...  positive   \n1  Product arrived labeled as Jumbo Salted Peanut...  negative   \n2  This is a confection that has been around a fe...  positive   \n3  If you are looking for the secret ingredient i...  positive   \n4  Great taffy at a great price.  There was a wid...  positive   \n\n                                          Suggestion  \n0  Thank you for your wonderful feedback, Eve! We...  \n1  Eve, we're sorry to hear about your experience...  \n2  Thank you for your wonderful feedback, Charlie...  \n3  Thank you for your wonderful feedback, Bob! We...  \n4  Thank you for your wonderful feedback, Charlie...  \n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"import pandas as pd\nfrom textblob import TextBlob\nimport random\nimport pickle\n\n# Veri setini yükleme\ndata = pd.read_csv('/kaggle/input/amazon-product-reviews/Reviews.csv')\n\n# Duygu analizi fonksiyonu\ndef analyze_sentiment(text):\n    analysis = TextBlob(text)\n    if analysis.sentiment.polarity > 0:\n        return 'positive'\n    elif analysis.sentiment.polarity < 0:\n        return 'negative'\n    else:\n        return 'neutral'\n\n# Duygu analizini uygulama\ndata['Sentiment'] = data['Text'].apply(analyze_sentiment)\n\n# Kullanıcı isimleri ve alışveriş geçmişini simüle etme\nuser_names = ['Alice', 'Bob', 'Charlie', 'Daisy', 'Eve']\npurchase_histories = [\"Vitality canned dog food\", \"Jumbo Salted Peanuts\", \"Confection\", \"Secret ingredient\", \"Taffy\"]\n\n# Rastgele isim ve geçmiş ekleyerek veri çerçevesini doldurma\ndata['User_Name'] = [random.choice(user_names) for _ in range(len(data))]\ndata['Purchase_History'] = [random.choice(purchase_histories) for _ in range(len(data))]\n\n# Geliştirilmiş öneri fonksiyonu\ndef generate_personalized_suggestion(sentiment, review_text, user_name, purchase_history):\n    keywords = [\"delivery\", \"quality\", \"taste\", \"packaging\", \"price\"]\n    matched_keywords = [word for word in keywords if word in review_text.lower()]\n\n    # Negatif yorumlar için\n    if sentiment == 'negative':\n        if matched_keywords:\n            suggestion = (f\"{user_name}, we appreciate your feedback on your purchase of '{purchase_history}'. \"\n                          f\"We're sorry to hear about issues with {', '.join(matched_keywords)}. \"\n                          \"Our team is working to address these concerns. \")\n            if 'delivery' in matched_keywords:\n                suggestion += \"Could you provide more details on the delivery issue? \"\n            if 'quality' in matched_keywords:\n                suggestion += \"Can you tell us what aspects of the quality could be enhanced? \"\n            if 'taste' in matched_keywords:\n                suggestion += \"Could you specify what could be improved in the flavor? \"\n            if 'packaging' in matched_keywords:\n                suggestion += \"If the packaging didn't meet your expectations, let us know how we can make it better. \"\n            if 'price' in matched_keywords:\n                suggestion += \"We strive to offer value; any suggestions on pricing are welcome! \"\n        else:\n            suggestion = (f\"{user_name}, we're sorry to hear about your experience with '{purchase_history}'. \"\n                          \"We would love to hear more details to help us improve.\")\n        suggestion += \" Please consider reaching out to our support team for immediate assistance.\"\n\n    # Nötr yorumlar için\n    elif sentiment == 'neutral':\n        suggestion = (f\"Thank you for your insights on '{purchase_history}', {user_name}. \"\n                      \"To enhance your experience, we recommend exploring additional features or products similar to what you've tried.\")\n\n    # Pozitif yorumlar için\n    else:  # positive\n        suggestion = (f\"Thank you for your wonderful feedback, {user_name}! We're thrilled that you enjoyed '{purchase_history}'. \"\n                      \"Have you tried similar products in our range? \")\n        suggestion += f\"You might also enjoy our '{random.choice(purchase_histories)}'!\"\n\n    return suggestion\n\n# Güncellenmiş öneri sütununu doldurma\ndata['Suggestion'] = data.apply(lambda row: generate_personalized_suggestion(row['Sentiment'], row['Text'], row['User_Name'], row['Purchase_History']), axis=1)\n\n# Fonksiyonları kaydetme\nwith open('suggestion_model.pkl', 'wb') as file:\n    pickle.dump((analyze_sentiment, generate_personalized_suggestion), file)\n\n# Çıktıyı görüntüleme\nprint(data[['User_Name', 'Purchase_History', 'Text', 'Sentiment', 'Suggestion']].head())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:05:21.452254Z","iopub.execute_input":"2024-11-11T10:05:21.452709Z","iopub.status.idle":"2024-11-11T10:12:33.96956Z","shell.execute_reply.started":"2024-11-11T10:05:21.452652Z","shell.execute_reply":"2024-11-11T10:12:33.968212Z"}},"outputs":[{"name":"stdout","text":"  User_Name          Purchase_History  \\\n0   Charlie         Secret ingredient   \n1   Charlie                     Taffy   \n2       Bob                     Taffy   \n3       Eve                     Taffy   \n4       Eve  Vitality canned dog food   \n\n                                                Text Sentiment  \\\n0  I have bought several of the Vitality canned d...  positive   \n1  Product arrived labeled as Jumbo Salted Peanut...  negative   \n2  This is a confection that has been around a fe...  positive   \n3  If you are looking for the secret ingredient i...  positive   \n4  Great taffy at a great price.  There was a wid...  positive   \n\n                                          Suggestion  \n0  Thank you for your wonderful feedback, Charlie...  \n1  Charlie, we're sorry to hear about your experi...  \n2  Thank you for your wonderful feedback, Bob! We...  \n3  Thank you for your wonderful feedback, Eve! We...  \n4  Thank you for your wonderful feedback, Eve! We...  \n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"# Kaydedilen fonksiyonları yükleme\nwith open('suggestion_model.pkl', 'rb') as file:\n    analyze_sentiment, generate_personalized_suggestion = pickle.load(file)\n\n# Test yorumu\ntest_text = \"The quality and taste were amazing, but I expected better packaging.\"\nsentiment = analyze_sentiment(test_text)\nsuggestion = generate_personalized_suggestion(sentiment, test_text, \"Alice\", \"Taffy\")\n\n# Üretilen öneriyi yazdırma\nprint(suggestion)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:12:33.97104Z","iopub.execute_input":"2024-11-11T10:12:33.971487Z","iopub.status.idle":"2024-11-11T10:12:33.97976Z","shell.execute_reply.started":"2024-11-11T10:12:33.971436Z","shell.execute_reply":"2024-11-11T10:12:33.978509Z"}},"outputs":[{"name":"stdout","text":"Thank you for your wonderful feedback, Alice! We're thrilled that you enjoyed 'Taffy'. Have you tried similar products in our range? You might also enjoy our 'Taffy'!\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"import pandas as pd\nfrom textblob import TextBlob\nimport random\nimport pickle\n\n# Veri setini yükleme\ndata = pd.read_csv('/kaggle/input/amazon-product-reviews/Reviews.csv')\n\n# Duygu analizi fonksiyonu\ndef analyze_sentiment(text):\n    analysis = TextBlob(text)\n    if analysis.sentiment.polarity > 0:\n        return 'positive'\n    elif analysis.sentiment.polarity < 0:\n        return 'negative'\n    else:\n        return 'neutral'\n\n# Duygu analizini uygulama\ndata['Sentiment'] = data['Text'].apply(analyze_sentiment)\n\n# Kullanıcı isimleri ve alışveriş geçmişini simüle etme\nuser_names = ['Alice', 'Bob', 'Charlie', 'Daisy', 'Eve']\npurchase_histories = [\"Vitality canned dog food\", \"Jumbo Salted Peanuts\", \"Confection\", \"Secret ingredient\", \"Taffy\"]\n\n# Rastgele isim ve geçmiş ekleyerek veri çerçevesini doldurma\ndata['User_Name'] = [random.choice(user_names) for _ in range(len(data))]\ndata['Purchase_History'] = [random.choice(purchase_histories) for _ in range(len(data))]\n\n# Geliştirilmiş öneri fonksiyonu\ndef generate_personalized_suggestion(sentiment, review_text, user_name, purchase_history):\n    keywords = [\"delivery\", \"quality\", \"taste\", \"packaging\", \"price\"]\n    matched_keywords = [word for word in keywords if word in review_text.lower()]\n\n    # Negatif yorumlar için\n    if sentiment == 'negative':\n        if matched_keywords:\n            suggestion = (f\"{user_name}, we appreciate your feedback on your purchase of '{purchase_history}'. \"\n                          f\"We're sorry to hear about issues with {', '.join(matched_keywords)}. \"\n                          \"Our team is working to address these concerns. \")\n            # Özel anahtar kelimelere göre ekstra tavsiye isteme\n            if 'delivery' in matched_keywords:\n                suggestion += \"Could you provide more details on the delivery issue so we can improve it? \"\n            if 'quality' in matched_keywords:\n                suggestion += \"Can you tell us what aspects of the quality could be enhanced? \"\n            if 'taste' in matched_keywords:\n                suggestion += \"Could you specify what could be improved in the flavor? \"\n            if 'packaging' in matched_keywords:\n                suggestion += \"If the packaging didn't meet your expectations, let us know how we can make it better. \"\n            if 'price' in matched_keywords:\n                suggestion += \"We strive to offer value; any suggestions on pricing are welcome! \"\n        else:\n            suggestion = (f\"{user_name}, we're sorry to hear about your experience with '{purchase_history}'. \"\n                          \"We would love to hear more details to help us improve.\")\n        suggestion += \" Please consider reaching out to our support team for immediate assistance.\"\n\n    # Nötr yorumlar için\n    elif sentiment == 'neutral':\n        suggestion = (f\"Thank you for your insights on '{purchase_history}', {user_name}. \"\n                      \"To enhance your experience, we recommend exploring additional features or products similar to what you've tried.\")\n\n    # Pozitif yorumlar için\n    else:  # positive\n        suggestion = (f\"Thank you for your wonderful feedback, {user_name}! We're thrilled that you enjoyed '{purchase_history}'. \"\n                      \"Have you tried similar products in our range? \")\n        # Benzer ürün önerisi yapma\n        suggestion += f\"You might also enjoy our '{random.choice(purchase_histories)}'!\"\n\n    return suggestion\n\n# Güncellenmiş öneri sütununu doldurma\ndata['Suggestion'] = data.apply(lambda row: generate_personalized_suggestion(row['Sentiment'], row['Text'], row['User_Name'], row['Purchase_History']), axis=1)\n\n# Modeli kaydetme\nmodel = None  # Burada modelinizi tanımlamanız gerekiyor (örneğin bir sınıflandırma modeli)\nwith open('naive_bayes_model.pkl', 'wb') as model_file:\n    pickle.dump(model, model_file)\n\n# TF-IDF vektörleştiricisini kaydetme (örneğin kullanıyorsanız)\ntfidf_vectorizer = None  # Burada TF-IDF vektörleştiricisini tanımlayın\nwith open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n    pickle.dump(tfidf_vectorizer, vectorizer_file)\n\n# Verileri CSV olarak kaydetme\ndata.to_csv('personalized_suggestions.csv', index=False)\n\n# Dosyaları Kaggle ortamından indirmenizi sağlayın\nimport shutil\n\n# Dosyaları yerel dizine taşımak için\nshutil.move('naive_bayes_model.pkl', '/kaggle/working/naive_bayes_model.pkl')\nshutil.move('tfidf_vectorizer.pkl', '/kaggle/working/tfidf_vectorizer.pkl')\nshutil.move('personalized_suggestions.csv', '/kaggle/working/personalized_suggestions.csv')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:12:33.98171Z","iopub.execute_input":"2024-11-11T10:12:33.982162Z","iopub.status.idle":"2024-11-11T10:19:56.675679Z","shell.execute_reply.started":"2024-11-11T10:12:33.982123Z","shell.execute_reply":"2024-11-11T10:19:56.674515Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/personalized_suggestions.csv'"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"import os\n\n# Çalışma dizinindeki dosyaları listeleme\nprint(os.listdir('/kaggle/working'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.676939Z","iopub.execute_input":"2024-11-11T10:19:56.677268Z","iopub.status.idle":"2024-11-11T10:19:56.683806Z","shell.execute_reply.started":"2024-11-11T10:19:56.677234Z","shell.execute_reply":"2024-11-11T10:19:56.682724Z"}},"outputs":[{"name":"stdout","text":"['naive_bayes_model.pkl', 'personalized_suggestions.csv', 'tfidf_vectorizer.pkl', 'suggestion_model.pkl', '.virtual_documents']\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"import joblib\njoblib.dump(nb_model, '/kaggle/working/nb_model.pkl')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.68524Z","iopub.execute_input":"2024-11-11T10:19:56.686053Z","iopub.status.idle":"2024-11-11T10:19:56.700454Z","shell.execute_reply.started":"2024-11-11T10:19:56.686001Z","shell.execute_reply":"2024-11-11T10:19:56.69919Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"['/kaggle/working/nb_model.pkl']"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"import os\nprint(os.path.exists('/kaggle/working/nb_model.pkl'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.702048Z","iopub.execute_input":"2024-11-11T10:19:56.703279Z","iopub.status.idle":"2024-11-11T10:19:56.709113Z","shell.execute_reply.started":"2024-11-11T10:19:56.703235Z","shell.execute_reply":"2024-11-11T10:19:56.708039Z"}},"outputs":[{"name":"stdout","text":"True\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import os\n\n# /kaggle/working dizinindeki dosyaları listele\nprint(os.listdir('/kaggle/working'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.710482Z","iopub.execute_input":"2024-11-11T10:19:56.710855Z","iopub.status.idle":"2024-11-11T10:19:56.723393Z","shell.execute_reply.started":"2024-11-11T10:19:56.710818Z","shell.execute_reply":"2024-11-11T10:19:56.721931Z"}},"outputs":[{"name":"stdout","text":"['nb_model.pkl', 'naive_bayes_model.pkl', 'personalized_suggestions.csv', 'tfidf_vectorizer.pkl', 'suggestion_model.pkl', '.virtual_documents']\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"import zipfile\n\n# ZIP dosyasını /kaggle/working dizininde oluşturuyoruz\nwith zipfile.ZipFile('/kaggle/working/nb_model.zip', 'w') as zipf:\n    zipf.write('/kaggle/working/nb_model.pkl', arcname='nb_model.pkl')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.725086Z","iopub.execute_input":"2024-11-11T10:19:56.725901Z","iopub.status.idle":"2024-11-11T10:19:56.740975Z","shell.execute_reply.started":"2024-11-11T10:19:56.725857Z","shell.execute_reply":"2024-11-11T10:19:56.739654Z"}},"outputs":[],"execution_count":36},{"cell_type":"code","source":"import joblib\n\n# Modelinizi kaydedin\njoblib.dump(nb_model, '/kaggle/working/nb_model.pkl')\nprint(\"Model başarıyla kaydedildi.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.742572Z","iopub.execute_input":"2024-11-11T10:19:56.743497Z","iopub.status.idle":"2024-11-11T10:19:56.759545Z","shell.execute_reply.started":"2024-11-11T10:19:56.743442Z","shell.execute_reply":"2024-11-11T10:19:56.758185Z"}},"outputs":[{"name":"stdout","text":"Model başarıyla kaydedildi.\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"import os\n\n# /kaggle/working dizinindeki dosyaları listeleyin\nprint(os.listdir('/kaggle/working'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.761336Z","iopub.execute_input":"2024-11-11T10:19:56.761818Z","iopub.status.idle":"2024-11-11T10:19:56.773999Z","shell.execute_reply.started":"2024-11-11T10:19:56.761775Z","shell.execute_reply":"2024-11-11T10:19:56.772841Z"}},"outputs":[{"name":"stdout","text":"['nb_model.pkl', 'naive_bayes_model.pkl', 'personalized_suggestions.csv', 'tfidf_vectorizer.pkl', 'suggestion_model.pkl', 'nb_model.zip', '.virtual_documents']\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"import os\nprint(os.listdir('/kaggle/working'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.775191Z","iopub.execute_input":"2024-11-11T10:19:56.775607Z","iopub.status.idle":"2024-11-11T10:19:56.788814Z","shell.execute_reply.started":"2024-11-11T10:19:56.775553Z","shell.execute_reply":"2024-11-11T10:19:56.78745Z"}},"outputs":[{"name":"stdout","text":"['nb_model.pkl', 'naive_bayes_model.pkl', 'personalized_suggestions.csv', 'tfidf_vectorizer.pkl', 'suggestion_model.pkl', 'nb_model.zip', '.virtual_documents']\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"from IPython.display import FileLink\n\n# Dosyanın tam yolu\nFileLink('/kaggle/working/nb_model.zip')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.790144Z","iopub.execute_input":"2024-11-11T10:19:56.790491Z","iopub.status.idle":"2024-11-11T10:19:56.805021Z","shell.execute_reply.started":"2024-11-11T10:19:56.790454Z","shell.execute_reply":"2024-11-11T10:19:56.803786Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/nb_model.zip","text/html":"<a href='/kaggle/working/nb_model.zip' target='_blank'>/kaggle/working/nb_model.zip</a><br>"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"import joblib\n\n# Vektörizer'i kaydetme\njoblib.dump(tfidf_vectorizer, '/kaggle/working/tfidf_vectorizer.pkl')\nprint(\"Vektörizer başarıyla kaydedildi.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.806278Z","iopub.execute_input":"2024-11-11T10:19:56.806668Z","iopub.status.idle":"2024-11-11T10:19:56.818138Z","shell.execute_reply.started":"2024-11-11T10:19:56.806621Z","shell.execute_reply":"2024-11-11T10:19:56.817008Z"}},"outputs":[{"name":"stdout","text":"Vektörizer başarıyla kaydedildi.\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"import os\n\n# /kaggle/working dizinini listele\nprint(os.listdir('/kaggle/working'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.819501Z","iopub.execute_input":"2024-11-11T10:19:56.820017Z","iopub.status.idle":"2024-11-11T10:19:56.839147Z","shell.execute_reply.started":"2024-11-11T10:19:56.819954Z","shell.execute_reply":"2024-11-11T10:19:56.837821Z"}},"outputs":[{"name":"stdout","text":"['nb_model.pkl', 'naive_bayes_model.pkl', 'personalized_suggestions.csv', 'tfidf_vectorizer.pkl', 'suggestion_model.pkl', 'nb_model.zip', '.virtual_documents']\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"# Vektörizer'i yükleme\nloaded_vectorizer = joblib.load('/kaggle/working/tfidf_vectorizer.pkl')\n\n# Yüklenen vektörizer'in tipini kontrol et\nprint(\"Vektörizer tipi:\", type(loaded_vectorizer))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.840908Z","iopub.execute_input":"2024-11-11T10:19:56.841319Z","iopub.status.idle":"2024-11-11T10:19:56.855026Z","shell.execute_reply.started":"2024-11-11T10:19:56.841277Z","shell.execute_reply":"2024-11-11T10:19:56.853565Z"}},"outputs":[{"name":"stdout","text":"Vektörizer tipi: <class 'NoneType'>\n","output_type":"stream"}],"execution_count":43},{"cell_type":"markdown","source":".\")\r\n","metadata":{}},{"cell_type":"code","source":"print(type(tfidf_vectorizer))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.856628Z","iopub.execute_input":"2024-11-11T10:19:56.857203Z","iopub.status.idle":"2024-11-11T10:19:56.868771Z","shell.execute_reply.started":"2024-11-11T10:19:56.857148Z","shell.execute_reply":"2024-11-11T10:19:56.867304Z"}},"outputs":[{"name":"stdout","text":"<class 'NoneType'>\n","output_type":"stream"}],"execution_count":44},{"cell_type":"code","source":"print(data.columns)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.870488Z","iopub.execute_input":"2024-11-11T10:19:56.871027Z","iopub.status.idle":"2024-11-11T10:19:56.883923Z","shell.execute_reply.started":"2024-11-11T10:19:56.870971Z","shell.execute_reply":"2024-11-11T10:19:56.882522Z"}},"outputs":[{"name":"stdout","text":"Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text',\n       'Sentiment', 'User_Name', 'Purchase_History', 'Suggestion'],\n      dtype='object')\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport joblib\n\n# Vektörizeri oluşturun ve eğitin\ntfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Gereken parametreleri ayarlayın\ntfidf_vectorizer.fit(data['Text'])  # 'Text' sütununu kullanıyoruz\n\nprint(\"Vektörizer başarıyla eğitildi.\")\n\n# Vektörizeri kaydedin\njoblib.dump(tfidf_vectorizer, '/kaggle/working/tfidf_vectorizer.pkl')\nprint(\"Vektörizer başarıyla kaydedildi.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:19:56.885393Z","iopub.execute_input":"2024-11-11T10:19:56.885858Z","iopub.status.idle":"2024-11-11T10:20:35.315085Z","shell.execute_reply.started":"2024-11-11T10:19:56.885815Z","shell.execute_reply":"2024-11-11T10:20:35.313872Z"}},"outputs":[{"name":"stdout","text":"Vektörizer başarıyla eğitildi.\nVektörizer başarıyla kaydedildi.\n","output_type":"stream"}],"execution_count":46},{"cell_type":"code","source":"import os\n\n# /kaggle/working dizinindeki dosyaları listeleyin\nprint(\"Dizin içeriği:\", os.listdir('/kaggle/working'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-11T10:20:35.31628Z","iopub.execute_input":"2024-11-11T10:20:35.316662Z","iopub.status.idle":"2024-11-11T10:20:35.322923Z","shell.execute_reply.started":"2024-11-11T10:20:35.316623Z","shell.execute_reply":"2024-11-11T10:20:35.32189Z"}},"outputs":[{"name":"stdout","text":"Dizin içeriği: ['nb_model.pkl', 'naive_bayes_model.pkl', 'personalized_suggestions.csv', 'tfidf_vectorizer.pkl', 'suggestion_model.pkl', 'nb_model.zip', '.virtual_documents']\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}